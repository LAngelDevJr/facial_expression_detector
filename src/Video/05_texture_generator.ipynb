{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5f1187",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextureMapGenerator:\n",
    "    \"\"\"\n",
    "    Implementa la generación de mapas de textura según el paper\n",
    "    \"Dynamic Sign Language Recognition Based on Convolutional Neural Networks and Texture Maps\".\n",
    "    \n",
    "    Genera dos tipos de mapas:\n",
    "    1. Skeleton Optical Spectra (SOS): Representación del movimiento global de landmarks faciales\n",
    "    2. Dynamic Images (Rank Pooling): Representación del movimiento local\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, width=400, height=400):\n",
    "        \"\"\"\n",
    "        Inicializa el generador de mapas de textura\n",
    "        \n",
    "        Args:\n",
    "            width: Ancho de los mapas de textura generados\n",
    "            height: Alto de los mapas de textura generados\n",
    "        \"\"\"\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        \n",
    "        # Parámetros para el modelo de color HSB (ecuación 1 del paper)\n",
    "        self.hmin = 0\n",
    "        self.hmax = 360\n",
    "        self.smin = 0.3\n",
    "        self.smax = 1.0\n",
    "        self.bmin = 0.3\n",
    "        self.bmax = 1.0\n",
    "        \n",
    "        # Cache para evitar cálculos repetidos\n",
    "        self.harmonic_cache = {0: 0}  # Números armónicos para Rank Pooling\n",
    "    \n",
    "    def _compute_harmonic_number(self, n):\n",
    "        \"\"\"\n",
    "        Calcula el n-ésimo número armónico H_n = 1 + 1/2 + 1/3 + ... + 1/n\n",
    "        Usado en la ecuación 5 del paper para Rank Pooling\n",
    "        \"\"\"\n",
    "        if n in self.harmonic_cache:\n",
    "            return self.harmonic_cache[n]\n",
    "        \n",
    "        # Calcular recursivamente usando valores en caché\n",
    "        if n-1 in self.harmonic_cache:\n",
    "            h_n = self.harmonic_cache[n-1] + 1/n\n",
    "        else:\n",
    "            h_n = sum(1/i for i in range(1, n+1))\n",
    "        \n",
    "        self.harmonic_cache[n] = h_n\n",
    "        return h_n\n",
    "    \n",
    "    def _hsb_to_rgb(self, h, s, b):\n",
    "        \"\"\"\n",
    "        Convierte de HSB a RGB (usado para visualización de SOS)\n",
    "        \n",
    "        Args:\n",
    "            h: Hue (0-360)\n",
    "            s: Saturation (0-1)\n",
    "            b: Brightness (0-1)\n",
    "            \n",
    "        Returns:\n",
    "            Tupla RGB (0-255, 0-255, 0-255)\n",
    "        \"\"\"\n",
    "        h = h / 360.0\n",
    "        c = b * s\n",
    "        x = c * (1 - abs((h * 6) % 2 - 1))\n",
    "        m = b - c\n",
    "        \n",
    "        if h < 1/6:\n",
    "            r, g, b = c, x, 0\n",
    "        elif h < 2/6:\n",
    "            r, g, b = x, c, 0\n",
    "        elif h < 3/6:\n",
    "            r, g, b = 0, c, x\n",
    "        elif h < 4/6:\n",
    "            r, g, b = 0, x, c\n",
    "        elif h < 5/6:\n",
    "            r, g, b = x, 0, c\n",
    "        else:\n",
    "            r, g, b = c, 0, x\n",
    "            \n",
    "        return (int((r + m) * 255), int((g + m) * 255), int((b + m) * 255))\n",
    "    \n",
    "    def generate_sos_maps(self, landmarks_sequence, facial_regions):\n",
    "        \"\"\"\n",
    "        Genera mapas de Skeleton Optical Spectra (SOS) para los landmarks faciales\n",
    "        Implementa la técnica descrita en la sección II.A.1 del paper\n",
    "        \n",
    "        Args:\n",
    "            landmarks_sequence: Lista de arrays de landmarks faciales (secuencia temporal)\n",
    "            facial_regions: Diccionario con índices de landmarks para cada región facial\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Mapas SOS para los planos XY, XZ e YZ\n",
    "        \"\"\"\n",
    "        if not landmarks_sequence or len(landmarks_sequence) < 2:\n",
    "            print(\"No hay suficientes landmarks para generar mapas SOS\")\n",
    "            return None\n",
    "        \n",
    "        # Crear mapas para cada plano\n",
    "        sos_xy = np.zeros((self.height, self.width, 3), dtype=np.uint8)\n",
    "        sos_xz = np.zeros((self.height, self.width, 3), dtype=np.uint8)\n",
    "        sos_yz = np.zeros((self.height, self.width, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Filtrar landmarks válidos\n",
    "        valid_landmarks = [lm for lm in landmarks_sequence if lm is not None and len(lm) > 0]\n",
    "        \n",
    "        if len(valid_landmarks) < 2:\n",
    "            print(\"No hay suficientes landmarks válidos para generar mapas SOS\")\n",
    "            return None\n",
    "        \n",
    "        # Extraer todos los landmarks para normalización\n",
    "        all_points = []\n",
    "        for landmarks in valid_landmarks:\n",
    "            # Convertir landmarks a lista de puntos 2D\n",
    "            if isinstance(landmarks, np.ndarray) and landmarks.ndim == 3:\n",
    "                points = landmarks.reshape(-1, 2)\n",
    "                all_points.extend(points)\n",
    "        \n",
    "        if not all_points:\n",
    "            print(\"No se pudieron extraer puntos válidos de los landmarks\")\n",
    "            return None\n",
    "            \n",
    "        all_points = np.array(all_points)\n",
    "        \n",
    "        # Calcular rango para normalización\n",
    "        min_x, min_y = np.min(all_points, axis=0)\n",
    "        max_x, max_y = np.max(all_points, axis=0)\n",
    "        \n",
    "        range_x = max_x - min_x\n",
    "        range_y = max_y - min_y\n",
    "        \n",
    "        if range_x <= 0 or range_y <= 0:\n",
    "            print(\"Rango inválido para normalización de puntos\")\n",
    "            return None\n",
    "        \n",
    "        # Calcular velocidades para cada punto facial\n",
    "        velocities = {}\n",
    "        for i in range(len(valid_landmarks) - 1):\n",
    "            try:\n",
    "                curr_landmarks = valid_landmarks[i]\n",
    "                next_landmarks = valid_landmarks[i+1]\n",
    "            \n",
    "            # Adaptar forma para cálculos\n",
    "                if isinstance(curr_landmarks, np.ndarray):\n",
    "                    if curr_landmarks.ndim == 3:\n",
    "                        curr_reshape = curr_landmarks.reshape(-1, 2)\n",
    "                    else:\n",
    "                        curr_reshape = curr_landmarks\n",
    "                else:\n",
    "                    continue  # Saltar si no podemos convertir\n",
    "                \n",
    "                if isinstance(next_landmarks, np.ndarray):\n",
    "                    if next_landmarks.ndim == 3:\n",
    "                        next_reshape = next_landmarks.reshape(-1, 2)\n",
    "                    else:\n",
    "                        next_reshape = next_landmarks\n",
    "                else:\n",
    "                    continue  # Saltar si no podemos convertir\n",
    "            \n",
    "            # Verificar que ambos landmarks tengan al menos un punto\n",
    "                if len(curr_reshape) == 0 or len(next_reshape) == 0:\n",
    "                    continue\n",
    "                \n",
    "            # Usar solo el número de puntos disponibles en ambos frames\n",
    "                min_points = min(len(curr_reshape), len(next_reshape))\n",
    "                \n",
    "                \n",
    "                \n",
    "                for j in range(min_points):\n",
    "                    if j not in velocities:\n",
    "                        velocities[j] = []\n",
    "                    try:\n",
    "                       if j < len(curr_reshape) and j < len(next_reshape):\n",
    "                            velocity = np.linalg.norm(next_reshape[j] - curr_reshape[j])\n",
    "                            velocities[j].append(velocity)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error al calcular velocidad para el punto {j}: {str(e)}\")\n",
    "                    # Continuar con el siguiente punto\n",
    "                        continue\n",
    "            except Exception as e:\n",
    "                print(f\"Error al procesar par de landmarks {i}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "                    \n",
    "                    \n",
    "        # Encontrar velocidad máxima para normalización\n",
    "        max_velocity = 1.0\n",
    "        for v_list in velocities.values():\n",
    "            if v_list:\n",
    "                max_v = np.max(v_list)\n",
    "                if max_v > max_velocity:\n",
    "                    max_velocity = max_v\n",
    "        \n",
    "        # Definir los 5 grupos de regiones faciales (adaptado del paper)\n",
    "        # K1 a K5 corresponden a las regiones definidas en el paper\n",
    "        facial_regions_grouped = {\n",
    "            'K1': facial_regions.get('indices_ojos', []),             # Equivalente a la región izquierda\n",
    "            'K2': facial_regions.get('indices_mandibula_menton', []), # Equivalente a la región derecha\n",
    "            'K3': facial_regions.get('indices_frente_cejas', []),     # Equivalente a brazo izquierdo\n",
    "            'K4': facial_regions.get('indices_boca', []),             # Equivalente a brazo derecho\n",
    "            'K5': facial_regions.get('indices_nariz', []) + \n",
    "                  facial_regions.get('indices_mejillas_pomulos', []) + \n",
    "                  facial_regions.get('indices_arrugas', [])           # Equivalente al cuerpo central\n",
    "        }\n",
    "        \n",
    "        # Función para normalizar coordenadas\n",
    "        def normalize_coords(x, y, z=0):\n",
    "            nx = int((x - min_x) / (range_x + 1e-10) * (self.width - 20)) + 10\n",
    "            ny = int((y - min_y) / (range_y + 1e-10) * (self.height - 20)) + 10\n",
    "            # Para la coordenada Z, usamos como aproximación la profundidad estimada (podría ser constante)\n",
    "            nz = int(z * (self.height / 4)) + (self.height // 2)\n",
    "            \n",
    "            # Asegurar que las coordenadas estén dentro de los límites\n",
    "            nx = max(0, min(self.width-1, nx))\n",
    "            ny = max(0, min(self.height-1, ny))\n",
    "            nz = max(0, min(self.height-1, nz))\n",
    "            \n",
    "            return nx, ny, nz\n",
    "        \n",
    "        # Crear un mapeo de cada punto a su región\n",
    "        point_to_region = {}\n",
    "        for region_name, indices in facial_regions_grouped.items():\n",
    "            for idx in indices:\n",
    "                point_to_region[idx] = region_name\n",
    "        \n",
    "        # Determinar a qué región pertenece cada índice en indices_clave\n",
    "        indices_clave = facial_regions.get('indices_clave', [])\n",
    "        for idx in indices_clave:\n",
    "            if idx not in point_to_region:\n",
    "                # Asignar puntos no clasificados a K5 (región central)\n",
    "                point_to_region[idx] = 'K5'\n",
    "        \n",
    "        # Número total de frames\n",
    "        n = len(valid_landmarks)\n",
    "        \n",
    "        # Dibujar cada punto en los mapas SOS según la ecuación 1 del paper\n",
    "        for t, landmarks in enumerate(valid_landmarks):\n",
    "            # Normalizar el tiempo para los cálculos de HSB\n",
    "            t_norm = t / max(1, n - 1)\n",
    "            \n",
    "            # Adaptar forma para cálculos\n",
    "            if isinstance(landmarks, np.ndarray) and landmarks.ndim == 3:\n",
    "                landmarks_reshaped = landmarks.reshape(-1, 2)\n",
    "            else:\n",
    "                landmarks_reshaped = landmarks\n",
    "            \n",
    "            for j, point in enumerate(landmarks_reshaped):\n",
    "                if j >= len(indices_clave):\n",
    "                    continue\n",
    "                    \n",
    "                idx = indices_clave[j]\n",
    "                region = point_to_region.get(idx, 'K5')\n",
    "                \n",
    "                # Implementar la ecuación 1 del paper para H, S, B\n",
    "                h = 0\n",
    "                if region == 'K1':\n",
    "                    h = (t_norm * (self.hmax - self.hmin)/2) + (self.hmin/2)\n",
    "                elif region == 'K2':\n",
    "                    h = (self.hmax/2) - (t_norm * (self.hmax - self.hmin)/2)\n",
    "                elif region == 'K3':\n",
    "                    h = self.hmax - (t_norm * (self.hmax - self.hmin)/2)\n",
    "                elif region == 'K4':\n",
    "                    h = (self.hmax/2) + (t_norm * (self.hmax - self.hmin)/2)\n",
    "                elif region == 'K5':\n",
    "                    h = 0  # Escala de grises para la región central\n",
    "                \n",
    "                # Calcular S y B basados en la velocidad\n",
    "                v_avg = 0\n",
    "                if j in velocities and velocities[j]:\n",
    "                    v_idx = min(t, len(velocities[j]) - 1)\n",
    "                    v_avg = velocities[j][v_idx] / max_velocity\n",
    "                \n",
    "                s = self.smin if region == 'K5' else (v_avg * (self.smax - self.smin) + self.smin)\n",
    "                \n",
    "                if region == 'K5':\n",
    "                    b = self.bmax - (t_norm * (self.bmax - self.bmin))\n",
    "                else:\n",
    "                    b = (v_avg * (self.bmax - self.bmin) + self.bmin)\n",
    "                \n",
    "                # Convertir HSB a RGB\n",
    "                color = self._hsb_to_rgb(h, s, b)\n",
    "                \n",
    "                # Extrar coordenadas X, Y del punto (y generar Z)\n",
    "                x, y = point[:2]\n",
    "                z = 0  # No tenemos Z real en landmarks 2D, usamos 0\n",
    "                \n",
    "                # Normalizar coordenadas para los tres planos\n",
    "                nx, ny, nz = normalize_coords(x, y, z)\n",
    "                \n",
    "                # Dibujar puntos en los mapas SOS\n",
    "                cv2.circle(sos_xy, (nx, ny), 2, color, -1)\n",
    "                cv2.circle(sos_xz, (nx, nz), 2, color, -1)\n",
    "                cv2.circle(sos_yz, (ny, nz), 2, color, -1)\n",
    "                \n",
    "                # Dibujar líneas entre puntos consecutivos para mejorar visualización\n",
    "                if t > 0 and j < len(valid_landmarks[t-1]):\n",
    "                    prev_point = valid_landmarks[t-1][j]\n",
    "                    if isinstance(prev_point, np.ndarray) and prev_point.ndim > 1:\n",
    "                        prev_point = prev_point.ravel()\n",
    "                    \n",
    "                    prev_x, prev_y = prev_point[:2]\n",
    "                    prev_nx, prev_ny, prev_nz = normalize_coords(prev_x, prev_y, z)\n",
    "                    \n",
    "                    # Dibujar líneas solo si los puntos no están muy lejos\n",
    "                    dist = np.sqrt((nx-prev_nx)**2 + (ny-prev_ny)**2)\n",
    "                    if dist < 30:  # Umbral para evitar líneas largas\n",
    "                        cv2.line(sos_xy, (prev_nx, prev_ny), (nx, ny), color, 1)\n",
    "                        cv2.line(sos_xz, (prev_nx, prev_nz), (nx, nz), color, 1)\n",
    "                        cv2.line(sos_yz, (prev_ny, prev_nz), (ny, nz), color, 1)\n",
    "        \n",
    "        return {\n",
    "            'DXY': sos_xy,\n",
    "            'DXZ': sos_xz,\n",
    "            'DYZ': sos_yz\n",
    "        }\n",
    "    \n",
    "    def generate_dynamic_image(self, frames, normalize=True):\n",
    "        \"\"\"\n",
    "        Genera una imagen dinámica a partir de frames mediante rank pooling\n",
    "        Implementa la técnica descrita en la sección II.A.2 del paper\n",
    "        \n",
    "        Args:\n",
    "            frames: Lista de frames de vídeo\n",
    "            normalize: Si True, normaliza la imagen resultante\n",
    "            \n",
    "        Returns:\n",
    "            Imagen dinámica que resume el movimiento\n",
    "        \"\"\"\n",
    "        if not frames or len(frames) < 2:\n",
    "            print(\"No hay suficientes frames para generar imagen dinámica\")\n",
    "            return None\n",
    "        \n",
    "        # Verifica que todos los frames tengan el mismo tamaño\n",
    "        height, width = frames[0].shape[:2]\n",
    "        for frame in frames[1:]:\n",
    "            if frame.shape[:2] != (height, width):\n",
    "                print(\"Los frames deben tener el mismo tamaño\")\n",
    "                return None\n",
    "        \n",
    "        # Número total de frames\n",
    "        T = len(frames)\n",
    "        \n",
    "        # Calcular los coeficientes alpha_t según la ecuación 5 del paper\n",
    "        alphas = np.zeros(T)\n",
    "        for t in range(1, T+1):  # t comienza desde 1 en el paper\n",
    "            H_t = self._compute_harmonic_number(t)\n",
    "            H_t_minus_1 = self._compute_harmonic_number(t-1)\n",
    "            H_T = self._compute_harmonic_number(T)\n",
    "            \n",
    "            # Ecuación 5 del paper\n",
    "            alphas[t-1] = 2 * (T - t + 1) - (T + 1) * (H_T - H_t_minus_1)\n",
    "        \n",
    "        # Normalizar alphas para estabilidad numérica\n",
    "        alphas = alphas / np.sum(np.abs(alphas))\n",
    "        \n",
    "        # Inicializar imagen dinámica\n",
    "        dynamic_image = np.zeros((height, width, 3), dtype=np.float32)\n",
    "        \n",
    "        # Aplicar ecuación 4 del paper: aproximación del rank pooling\n",
    "        for t in range(T):\n",
    "            # Convertir frame a float32 para cálculos\n",
    "            frame = frames[t].astype(np.float32)\n",
    "            \n",
    "            # Ponderar frame por su coeficiente alpha_t\n",
    "            dynamic_image += alphas[t] * frame\n",
    "        \n",
    "        if normalize:\n",
    "            # Normalizar a rango 0-255\n",
    "            min_val = np.min(dynamic_image)\n",
    "            max_val = np.max(dynamic_image)\n",
    "            \n",
    "            if max_val > min_val:\n",
    "                dynamic_image = 255 * (dynamic_image - min_val) / (max_val - min_val)\n",
    "            \n",
    "        # Convertir a uint8 para visualización\n",
    "        dynamic_image = np.clip(dynamic_image, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        return dynamic_image\n",
    "    \n",
    "    def extract_representative_frame(self, frames, landmarks):\n",
    "        \"\"\"\n",
    "        Extrae el frame más representativo de una secuencia, basado en la\n",
    "        sección II.B del paper (detección de segmento con menor aceleración)\n",
    "        \n",
    "        Args:\n",
    "            frames: Lista de frames\n",
    "            landmarks: Lista de landmarks correspondientes\n",
    "            \n",
    "        Returns:\n",
    "            Frame representativo con la mejor configuración facial\n",
    "        \"\"\"\n",
    "        if not frames or not landmarks or len(frames) < 3:\n",
    "            print(\"No hay suficientes datos para extraer frame representativo\")\n",
    "            return None\n",
    "        \n",
    "        # Filtrar landmarks y frames válidos\n",
    "        valid_data = [(f, l) for f, l in zip(frames, landmarks) if f is not None and l is not None]\n",
    "        if len(valid_data) < 3:\n",
    "            print(\"No hay suficientes datos válidos\")\n",
    "            return None\n",
    "            \n",
    "        frames_valid, landmarks_valid = zip(*valid_data)\n",
    "        \n",
    "        # 1. Calcular punto central para cada set de landmarks\n",
    "        center_points = []\n",
    "        for lm in landmarks_valid:\n",
    "            if isinstance(lm, np.ndarray):\n",
    "                if lm.ndim == 3:\n",
    "                    points = lm.reshape(-1, 2)\n",
    "                else:\n",
    "                    points = lm\n",
    "                center = np.mean(points, axis=0)\n",
    "                center_points.append(center)\n",
    "            else:\n",
    "                # Si no es un array numpy, intentar convertir\n",
    "                try:\n",
    "                    points = np.array(lm).reshape(-1, 2)\n",
    "                    center = np.mean(points, axis=0)\n",
    "                    center_points.append(center)\n",
    "                except:\n",
    "                    print(\"Error al procesar landmarks, formato no válido\")\n",
    "                    return None\n",
    "        \n",
    "        # 2. Calcular distancias entre puntos consecutivos (ecuación 6)\n",
    "        distances = []\n",
    "        for i in range(len(center_points) - 1):\n",
    "            dist = np.linalg.norm(center_points[i+1] - center_points[i])\n",
    "            distances.append(dist)\n",
    "        \n",
    "        # 3. Calcular distancias acumulativas y velocidades (ecuación 7)\n",
    "        cum_distances = np.cumsum(distances)\n",
    "        velocities = []\n",
    "        for i in range(len(cum_distances)):\n",
    "            velocity = cum_distances[i] / (i + 1)\n",
    "            velocities.append(velocity)\n",
    "        \n",
    "        # 4. Calcular aceleraciones (ecuación 8)\n",
    "        accelerations = []\n",
    "        for i in range(len(velocities) - 1):\n",
    "            acceleration = velocities[i+1] - velocities[i]\n",
    "            accelerations.append(acceleration)\n",
    "        \n",
    "        # 5. Dividir en M=3 segmentos y calcular desviación estándar\n",
    "        M = 3  # Número de segmentos como en el paper\n",
    "        if len(accelerations) < M:\n",
    "            M = len(accelerations)\n",
    "            \n",
    "        segments = []\n",
    "        segment_size = len(accelerations) // M\n",
    "        \n",
    "        for i in range(M):\n",
    "            start_idx = i * segment_size\n",
    "            end_idx = start_idx + segment_size if i < M-1 else len(accelerations)\n",
    "            segment = accelerations[start_idx:end_idx]\n",
    "            sd = np.std(segment)\n",
    "            segments.append((start_idx, end_idx, sd))\n",
    "        \n",
    "        # 6. Seleccionar segmento con menor SD (movimiento más estable)\n",
    "        min_sd_segment = min(segments, key=lambda x: x[2])\n",
    "        start_idx, end_idx, _ = min_sd_segment\n",
    "        \n",
    "        # Convertir índices de aceleración a índices de frames\n",
    "        # La aceleración i corresponde al frame i+2\n",
    "        start_frame_idx = start_idx + 2\n",
    "        end_frame_idx = min(end_idx + 2, len(frames_valid))\n",
    "        \n",
    "        # 7. Extraer frames del segmento y calcular nitidez\n",
    "        frame_sharpness = []\n",
    "        for i in range(start_frame_idx, end_frame_idx):\n",
    "            frame = frames_valid[i]\n",
    "            \n",
    "            # Calcular nitidez usando el Laplaciano (medida de energía)\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "            \n",
    "            frame_sharpness.append((i, sharpness))\n",
    "        \n",
    "        if not frame_sharpness:\n",
    "            # Si no hay frames con nitidez calculada, usar el frame central\n",
    "            mid_idx = len(frames_valid) // 2\n",
    "            return frames_valid[mid_idx]\n",
    "        \n",
    "        # 8. Seleccionar el frame más nítido\n",
    "        best_idx, _ = max(frame_sharpness, key=lambda x: x[1])\n",
    "        \n",
    "        return frames_valid[best_idx]\n",
    "    \n",
    "    def generate_all_texture_maps(self, frames_buffer, landmarks_buffer, facial_regions):\n",
    "        \"\"\"\n",
    "        Genera todos los mapas de textura mencionados en el paper:\n",
    "        - SOS (Skeleton Optical Spectra): DXY, DXZ, DYZ\n",
    "        - Dynamic Image (Rank Pooling): DC\n",
    "        - Frame representativo: HC\n",
    "        \n",
    "        Args:\n",
    "            frames_buffer: Buffer de frames de video\n",
    "            landmarks_buffer: Buffer de landmarks faciales\n",
    "            facial_regions: Diccionario con regiones faciales\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Todos los mapas de textura generados\n",
    "        \"\"\"\n",
    "        all_maps = {}\n",
    "        \n",
    "        # Filtrar frames y landmarks válidos\n",
    "        valid_data = []\n",
    "        for f, l in zip(frames_buffer, landmarks_buffer):\n",
    "            if f is not None and l is not None:\n",
    "            # Verificar que landmark tenga datos válidos\n",
    "                try:\n",
    "                    if isinstance(l, np.ndarray):\n",
    "                        if l.size > 0:  # Verificar que no esté vacío\n",
    "                            valid_data.append((f, l))\n",
    "                    else:\n",
    "                        valid_data.append((f, l))\n",
    "                except:\n",
    "                # Si hay error al procesar el landmark, omitirlo\n",
    "                    continue\n",
    "    \n",
    "        if len(valid_data) < 3:\n",
    "            print(\"No hay suficientes datos válidos para generar mapas de textura\")\n",
    "            return {}\n",
    "        \n",
    "        frames_valid, landmarks_valid = zip(*valid_data)\n",
    "    \n",
    "        try:\n",
    "        # 1. Generar mapas SOS\n",
    "            print(\"Generando mapas SOS...\")\n",
    "            sos_maps = self.generate_sos_maps(landmarks_valid, facial_regions)\n",
    "            if sos_maps:\n",
    "                all_maps.update(sos_maps)\n",
    "                print(\"Mapas SOS generados con éxito\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al generar mapas SOS: {str(e)}\")\n",
    "    \n",
    "        try:\n",
    "        # 2. Generar imagen dinámica a color\n",
    "            print(\"Generando mapa dinámico DC...\")\n",
    "            dynamic_color = self.generate_dynamic_image(frames_valid)\n",
    "            if dynamic_color is not None:\n",
    "                all_maps['DC'] = dynamic_color\n",
    "                print(\"Mapa dinámico DC generado con éxito\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al generar mapa dinámico DC: {str(e)}\")\n",
    "    \n",
    "        try:\n",
    "        # 3. Extraer frame representativo\n",
    "            print(\"Extrayendo frame representativo HC...\")\n",
    "            representative_frame = self.extract_representative_frame(frames_valid, landmarks_valid)\n",
    "            if representative_frame is not None:\n",
    "                all_maps['HC'] = representative_frame\n",
    "                print(\"Frame representativo HC extraído con éxito\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al extraer frame representativo HC: {str(e)}\")\n",
    "    \n",
    "        return all_maps\n",
    "    \n",
    "    \n",
    "    def visualize_texture_maps(self, texture_maps):\n",
    "        \"\"\"\n",
    "        Visualiza los mapas de textura generados\n",
    "        \n",
    "        Args:\n",
    "            texture_maps: Diccionario con los mapas de textura\n",
    "            \n",
    "        Returns:\n",
    "            Figura de matplotlib con la visualización\n",
    "        \"\"\"\n",
    "        if not texture_maps:\n",
    "            print(\"No hay mapas de textura para visualizar\")\n",
    "            return None\n",
    "        \n",
    "        num_maps = len(texture_maps)\n",
    "        fig, axes = plt.subplots(1, num_maps, figsize=(num_maps*5, 5))\n",
    "        \n",
    "        # Si solo hay un mapa, axes no es un array\n",
    "        if num_maps == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        # Mostrar cada mapa\n",
    "        for i, (map_name, texture_map) in enumerate(texture_maps.items()):\n",
    "            # Convertir de BGR a RGB para matplotlib\n",
    "            if texture_map.ndim == 3:\n",
    "                texture_map_rgb = cv2.cvtColor(texture_map, cv2.COLOR_BGR2RGB)\n",
    "            else:\n",
    "                texture_map_rgb = texture_map\n",
    "            \n",
    "            axes[i].imshow(texture_map_rgb)\n",
    "            axes[i].set_title(map_name)\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def create_enhanced_summary_video(self, texture_maps, frames, output_path, fps=30):\n",
    "        \"\"\"\n",
    "        Crea un video resumen mejorado combinando keyframes con mapas de textura\n",
    "        Usa los mapas de textura para crear transiciones más suaves y naturales\n",
    "        \n",
    "        Args:\n",
    "            texture_maps: Diccionario con mapas de textura\n",
    "            frames: Lista de frames para el video\n",
    "            output_path: Ruta donde guardar el video\n",
    "            fps: Frames por segundo del video de salida\n",
    "            \n",
    "        Returns:\n",
    "            Ruta al video generado\n",
    "        \"\"\"\n",
    "        if not frames or not texture_maps:\n",
    "            print(\"No hay suficientes datos para crear el video\")\n",
    "            return None\n",
    "        \n",
    "        # Extraer dimensiones del primer frame\n",
    "        height, width = frames[0].shape[:2]\n",
    "        \n",
    "        # Configurar el escritor de video\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        # Asegurar que todos los mapas de textura tengan el mismo tamaño\n",
    "        resized_maps = {}\n",
    "        for name, texture_map in texture_maps.items():\n",
    "            if texture_map.shape[:2] != (height, width):\n",
    "                resized_maps[name] = cv2.resize(texture_map, (width, height))\n",
    "            else:\n",
    "                resized_maps[name] = texture_map\n",
    "        \n",
    "        # Escribir introducción con mapas de textura (2 segundos)\n",
    "        intro_frames = int(fps * 2)\n",
    "        for i in range(intro_frames):\n",
    "            # Crear composición de mapas de textura\n",
    "            intro_frame = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "            \n",
    "            # Mostrar diferentes mapas en secuencia\n",
    "            map_duration = intro_frames // len(resized_maps)\n",
    "            map_index = i // map_duration\n",
    "            map_names = list(resized_maps.keys())\n",
    "            \n",
    "            if map_index < len(map_names):\n",
    "                current_map = resized_maps[map_names[map_index]].copy()\n",
    "                \n",
    "                # Añadir texto explicativo\n",
    "                cv2.putText(current_map, f\"Mapa de textura: {map_names[map_index]}\", \n",
    "                           (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                \n",
    "                intro_frame = current_map\n",
    "            \n",
    "            out.write(intro_frame)\n",
    "        \n",
    "        # Escribir secuencia principal con frames y transiciones basadas en mapas\n",
    "        for i in range(len(frames) - 1):\n",
    "            # Escribir el frame actual\n",
    "            out.write(frames[i])\n",
    "            \n",
    "            # Crear transición al siguiente frame\n",
    "            transition_frames = 3  # Número de frames para transición\n",
    "            for t in range(transition_frames):\n",
    "                alpha = (t + 1) / (transition_frames + 1)\n",
    "                \n",
    "                # Transición básica entre frames\n",
    "                transition = cv2.addWeighted(frames[i], 1-alpha, frames[i+1], alpha, 0)\n",
    "                \n",
    "                # Mejorar la transición con información de mapas de textura\n",
    "                if 'DXY' in resized_maps:\n",
    "                    # Usar el mapa DXY para enfatizar movimiento en la transición\n",
    "                    # Aplicar una ligera mezcla con el mapa de textura\n",
    "                    transition = cv2.addWeighted(transition, 0.9, \n",
    "                                                resized_maps['DXY'], 0.1, 0)\n",
    "                \n",
    "                out.write(transition)\n",
    "        \n",
    "        # Escribir el último frame\n",
    "        out.write(frames[-1])\n",
    "        \n",
    "        # Cerrar el escritor\n",
    "        out.release()\n",
    "        \n",
    "        print(f\"Video resumen mejorado creado en {output_path}\")\n",
    "        return output_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
