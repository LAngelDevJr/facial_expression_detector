{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ff8b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyFrameDetector:\n",
    "    def __init__(self):\n",
    "        # Matrices para el mecanismo de atención (inicializadas aleatoriamente)\n",
    "        self.feature_dim = 512\n",
    "        self.W1 = np.random.randn(self.feature_dim, self.feature_dim) * 0.01\n",
    "        self.W2 = np.random.randn(self.feature_dim, self.feature_dim) * 0.01\n",
    "        self.W3 = np.random.randn(self.feature_dim, self.feature_dim) * 0.01\n",
    "        \n",
    "        # Capas adicionales para el cálculo de importancia\n",
    "        self.U = np.random.randn(self.feature_dim, self.feature_dim) * 0.01\n",
    "        self.L1_weights = np.random.randn(256, self.feature_dim) * 0.01\n",
    "        self.L2_weights = np.random.randn(1, 256) * 0.01\n",
    "    \n",
    "    def extract_features_from_landmarks(self, landmarks_points):\n",
    "        \"\"\"Extrae un vector de características simplificado a partir de landmarks\"\"\"\n",
    "        if landmarks_points is None:\n",
    "            return None\n",
    "            \n",
    "        # Aplanar landmarks a un vector\n",
    "        features = landmarks_points.reshape(-1)\n",
    "        \n",
    "        # Para una implementación real, aquí se usaría un modelo como ResNet\n",
    "        # Simulamos un vector de dimensión feature_dim\n",
    "        if len(features) > self.feature_dim:\n",
    "            features = features[:self.feature_dim]\n",
    "        elif len(features) < self.feature_dim:\n",
    "            padding = np.zeros(self.feature_dim - len(features))\n",
    "            features = np.concatenate([features, padding])\n",
    "            \n",
    "        return features\n",
    "    \n",
    "    def compute_importance_score(self, feature_sequence):\n",
    "        \"\"\"Implementa las fórmulas 1-6 del paper para calcular la importancia de frames\"\"\"\n",
    "        K = len(feature_sequence)\n",
    "        importance_scores = []\n",
    "        \n",
    "        for k in range(K):\n",
    "            # Fórmula 1: Cálculo de correlación entre features\n",
    "            alpha_k = np.zeros(K)\n",
    "            for i in range(K):\n",
    "                # αk,i = (W1pi)T(W2pk)\n",
    "                alpha_k[i] = np.dot(np.dot(self.W1, feature_sequence[i]), \n",
    "                                   np.dot(self.W2, feature_sequence[k]))\n",
    "            \n",
    "            # Fórmula 2: Normalización con softmax\n",
    "            # α˜k = Softmax(αk)\n",
    "            alpha_k_normalized = softmax(alpha_k)\n",
    "            \n",
    "            # Fórmula 4: Ponderación de características\n",
    "            # bk = Σ(i=1 to K) α˜k,i(W3pk)\n",
    "            b_k = np.zeros_like(feature_sequence[k])\n",
    "            for i in range(K):\n",
    "                b_k += alpha_k_normalized[i] * np.dot(self.W3, feature_sequence[k])\n",
    "            \n",
    "            # Fórmula 5: Transformación y residual\n",
    "            # gk = Norm(Dropout(Ubk + pk))\n",
    "            # Simplificado sin dropout y normalización\n",
    "            g_k = np.dot(self.U, b_k) + feature_sequence[k]\n",
    "            \n",
    "            # Fórmula 6: Capas finales para calcular la puntuación\n",
    "            # zk = L2(L1(gk))\n",
    "            l1_output = np.maximum(0, np.dot(self.L1_weights, g_k))  # ReLU\n",
    "            score = 1 / (1 + np.exp(-np.dot(self.L2_weights, l1_output)[0]))  # Sigmoid\n",
    "            \n",
    "            importance_scores.append(score)\n",
    "        \n",
    "        return importance_scores\n",
    "    \n",
    "    def select_key_frames(self, frames_buffer, landmarks_buffer, movement_values):\n",
    "\n",
    "    # Filtrar landmarks válidos y sus índices correspondientes\n",
    "        valid_landmarks = [landmarks for landmarks in landmarks_buffer if landmarks is not None]\n",
    "        valid_indices = [i for i, landmarks in enumerate(landmarks_buffer) if landmarks is not None]\n",
    "    \n",
    "        if len(valid_landmarks) < 3:  # Necesitamos al menos 3 puntos para calcular aceleración\n",
    "            return []\n",
    "    \n",
    "    # 1. Calcular puntos de movimiento para un punto de referencia (p.ej. nariz o centro de la cara)\n",
    "    # Usamos el punto central como representativo del movimiento facial\n",
    "        punto_central = []\n",
    "        for landmarks in valid_landmarks:\n",
    "        # Calcular punto central promediando todos los landmarks\n",
    "            if len(landmarks) > 0:\n",
    "                puntos = landmarks.reshape(-1, 2)\n",
    "                punto_central.append(np.mean(puntos, axis=0))\n",
    "    \n",
    "    # 2. Calcular distancias entre puntos consecutivos\n",
    "        distancias = []\n",
    "        for i in range(len(punto_central) - 1):\n",
    "            dist = np.linalg.norm(punto_central[i+1] - punto_central[i])\n",
    "            distancias.append(dist)\n",
    "    \n",
    "        if not distancias:\n",
    "            return []\n",
    "    \n",
    "    # 3. Calcular velocidades acumulativas y velocidad instantánea\n",
    "        dist_acum = np.cumsum(distancias)\n",
    "        velocidades = []\n",
    "        for i in range(len(dist_acum)):\n",
    "            velocidades.append(dist_acum[i] / (i + 1))\n",
    "    \n",
    "    # 4. Calcular aceleraciones (cambio en velocidad)\n",
    "        aceleraciones = []\n",
    "        for i in range(len(velocidades) - 1):\n",
    "            aceleraciones.append(velocidades[i+1] - velocidades[i])\n",
    "    \n",
    "        if not aceleraciones:\n",
    "            return []\n",
    "    \n",
    "    # 5. Dividir la trayectoria en 3 segmentos y calcular desviación estándar para cada uno\n",
    "        num_segmentos = min(3, len(aceleraciones))\n",
    "        segmentos = []\n",
    "        longitud_segmento = len(aceleraciones) // num_segmentos\n",
    "    \n",
    "        for i in range(num_segmentos):\n",
    "            inicio = i * longitud_segmento\n",
    "            fin = inicio + longitud_segmento if i < num_segmentos - 1 else len(aceleraciones)\n",
    "            segmento = aceleraciones[inicio:fin]\n",
    "            desviacion = np.std(segmento)\n",
    "            segmentos.append((inicio, fin, desviacion))\n",
    "    \n",
    "    # 6. Seleccionar segmento con menor desviación estándar (movimiento más estable)\n",
    "        segmento_estable = min(segmentos, key=lambda x: x[2])\n",
    "        inicio_estable, fin_estable, _ = segmento_estable\n",
    "    \n",
    "    # 7. Seleccionar frames del segmento estable\n",
    "    # Ajustar índices para corresponder a los frames originales\n",
    "        inicio_frames = valid_indices[inicio_estable] if inicio_estable < len(valid_indices) else 0\n",
    "        fin_frames = valid_indices[min(fin_estable, len(valid_indices)-1)]\n",
    "    \n",
    "    # Asegurarse de que el rango de frames es válido\n",
    "        inicio_frames = max(0, inicio_frames)\n",
    "        fin_frames = min(len(frames_buffer) - 1, fin_frames)\n",
    "    \n",
    "    # 8. Calcular nitidez para cada frame en el segmento estable\n",
    "        frames_nitidez = []\n",
    "        for i in range(inicio_frames, fin_frames + 1):\n",
    "            if i >= len(frames_buffer):\n",
    "                continue\n",
    "            \n",
    "            frame = frames_buffer[i]\n",
    "            if frame is None:\n",
    "                continue\n",
    "            \n",
    "        # Convertir a escala de grises para calcular nitidez\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Calcular nitidez usando el operador laplaciano\n",
    "            nitidez = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "            frames_nitidez.append((i, nitidez))\n",
    "    \n",
    "    # 9. Seleccionar los frames más nítidos\n",
    "        if not frames_nitidez:\n",
    "            return []\n",
    "        \n",
    "    # Ordenar por nitidez y seleccionar los mejores\n",
    "        frames_nitidez.sort(key=lambda x: x[1], reverse=True)\n",
    "        num_frames_seleccionar = min(3, len(frames_nitidez))\n",
    "        indices_seleccionados = [idx for idx, _ in frames_nitidez[:num_frames_seleccionar]]\n",
    "        indices_seleccionados.sort()  # Mantener orden temporal\n",
    "    ##xxx\n",
    "    # 10. Devolver los frames seleccionados\n",
    "        key_frames = [frames_buffer[idx] for idx in indices_seleccionados if idx < len(frames_buffer)]\n",
    "        return key_frames"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
