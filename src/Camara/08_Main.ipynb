{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b8e070d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando detección de expresiones faciales desde la cámara 0\n",
      "Los resultados se guardarán en: C:/Users/Usuario/Documents/facial_expression_detector/data/output\n",
      "Solapamiento entre frente_cejas y ojos: 8 puntos\n",
      "Solapamiento entre frente_cejas y nariz: 1 puntos\n",
      "Solapamiento entre frente_cejas y mejillas: 5 puntos\n",
      "Solapamiento entre frente_cejas y boca: 6 puntos\n",
      "Solapamiento entre frente_cejas y mandibula: 4 puntos\n",
      "Solapamiento entre frente_cejas y arrugas: 6 puntos\n",
      "Solapamiento entre ojos y frente_cejas: 8 puntos\n",
      "Solapamiento entre ojos y nariz: 2 puntos\n",
      "Solapamiento entre ojos y boca: 5 puntos\n",
      "Solapamiento entre nariz y frente_cejas: 1 puntos\n",
      "Solapamiento entre nariz y ojos: 2 puntos\n",
      "Solapamiento entre nariz y mejillas: 7 puntos\n",
      "Solapamiento entre nariz y boca: 1 puntos\n",
      "Solapamiento entre nariz y mandibula: 21 puntos\n",
      "Solapamiento entre nariz y arrugas: 11 puntos\n",
      "Solapamiento entre mejillas y frente_cejas: 5 puntos\n",
      "Solapamiento entre mejillas y nariz: 7 puntos\n",
      "Solapamiento entre mejillas y boca: 3 puntos\n",
      "Solapamiento entre mejillas y mandibula: 1 puntos\n",
      "Solapamiento entre mejillas y arrugas: 4 puntos\n",
      "Solapamiento entre boca y frente_cejas: 6 puntos\n",
      "Solapamiento entre boca y ojos: 5 puntos\n",
      "Solapamiento entre boca y nariz: 1 puntos\n",
      "Solapamiento entre boca y mejillas: 3 puntos\n",
      "Solapamiento entre mandibula y frente_cejas: 4 puntos\n",
      "Solapamiento entre mandibula y nariz: 21 puntos\n",
      "Solapamiento entre mandibula y mejillas: 1 puntos\n",
      "Solapamiento entre mandibula y arrugas: 25 puntos\n",
      "Solapamiento entre arrugas y frente_cejas: 6 puntos\n",
      "Solapamiento entre arrugas y nariz: 11 puntos\n",
      "Solapamiento entre arrugas y mejillas: 4 puntos\n",
      "Solapamiento entre arrugas y mandibula: 25 puntos\n",
      "Conteo de puntos por región:\n",
      "  frente_cejas: 54 puntos\n",
      "  ojos: 103 puntos\n",
      "  nariz: 0 puntos\n",
      "  mejillas: 0 puntos\n",
      "  boca: 0 puntos\n",
      "  mandibula: 0 puntos\n",
      "  arrugas: 0 puntos\n",
      "  otros: 40 puntos\n",
      "FPS: 30.0\n",
      "Procesando 1 de cada 1 frames para optimizar velocidad\n",
      "Iniciando captura de cámara. Presiona ESC para detener.\n",
      "Procesamiento completado en 1.74 segundos\n",
      "Velocidad promedio: 22.36 frames por segundo\n",
      "No se detectaron keyframes\n",
      "No se detectaron expresiones faciales\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Importar todos los módulos necesarios\n",
    "%run 01_constante.ipynb\n",
    "%run 02_landmarks.ipynb\n",
    "%run 03_optical_flow.ipynb\n",
    "%run 04_keyframe.ipynb\n",
    "%run 05_texture_generator.ipynb\n",
    "%run 06_CameraProcessor.ipynb\n",
    "%run 07_result_analyzer.ipynb\n",
    "\n",
    "def main(camera_index=0, output_folder=\"output_camara\", display=True, use_texture_maps=True, max_time=None):\n",
    "    \"\"\"\n",
    "    Función principal que ejecuta el pipeline de detección de expresiones faciales desde la cámara.\n",
    "    \n",
    "    Args:\n",
    "        camera_index: Índice de la cámara (0 para la predeterminada)\n",
    "        output_folder: Carpeta donde guardar resultados\n",
    "        display: Si True, muestra visualización en tiempo real\n",
    "        use_texture_maps: Si True, genera mapas de textura para mejorar el resumen\n",
    "        max_time: Tiempo máximo en segundos para capturar (None para continuar hasta ESC)\n",
    "    \"\"\"\n",
    "    print(f\"Iniciando detección de expresiones faciales desde la cámara {camera_index}\")\n",
    "    print(f\"Los resultados se guardarán en: {output_folder}\")\n",
    "    \n",
    "    # Crear carpeta de salida si no existe\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Inicializar procesador de cámara\n",
    "    processor = CameraProcessor()\n",
    "    \n",
    "    # Procesar cámara\n",
    "    try:\n",
    "        if use_texture_maps:\n",
    "            result = processor.process_camera(camera_index, output_folder, display, use_texture_maps=True, max_time=max_time)\n",
    "        else:\n",
    "            result = processor.process_camera(camera_index, output_folder, display, max_time=max_time)\n",
    "        \n",
    "        # Extraer resultados\n",
    "        if use_texture_maps:\n",
    "            keyframes, keyframe_indices, texture_maps = result\n",
    "        else:\n",
    "            keyframes, keyframe_indices = result\n",
    "            texture_maps = {}\n",
    "        \n",
    "        if not keyframes:\n",
    "            print(\"No se detectaron expresiones faciales\")\n",
    "            return\n",
    "        \n",
    "        # Mostrar estadísticas\n",
    "        print(f\"\\nEstadísticas:\")\n",
    "        print(f\"- Total de keyframes detectados: {len(keyframes)}\")\n",
    "        if len(keyframe_indices) > 1:\n",
    "            gaps = np.diff(keyframe_indices)\n",
    "            print(f\"- Distancia promedio entre keyframes: {np.mean(gaps):.2f} frames\")\n",
    "            print(f\"- Distancia mínima entre keyframes: {np.min(gaps)} frames\")\n",
    "            print(f\"- Distancia máxima entre keyframes: {np.max(gaps)} frames\")\n",
    "        \n",
    "        # Si se usaron mapas de textura, mostrar información adicional\n",
    "        if use_texture_maps and texture_maps:\n",
    "            print(f\"- Mapas de textura generados: {', '.join(texture_maps.keys())}\")\n",
    "        \n",
    "        print(\"\\nProcesamiento completado. Revisa los resultados en la carpeta de salida.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error durante el procesamiento: {str(e)}\")\n",
    "\n",
    "# Ejecutar si este archivo es el principal\n",
    "if __name__ == \"__main__\":\n",
    "    # Puedes personalizar estos parámetros según necesites\n",
    "    camera_idx = 0  # 0 para la cámara predeterminada\n",
    "    output_dir = \"C:/Users/Usuario/Documents/facial_expression_detector/data/output\"  # Carpeta para guardar resultados\n",
    "    use_display = True  # Mostrar visualización en tiempo real\n",
    "    use_texture_maps = True  # Generar mapas de textura\n",
    "    recording_time = 60  # Grabar durante 60 segundos, None para continuar hasta ESC\n",
    "    \n",
    "    main(camera_idx, output_dir, use_display, use_texture_maps, recording_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
